1. Choice of base image in each container.
---------------------------------------


Back end
--------

For back end i used node:14 which has an environment ideal for installation of all the required dependencies. For the second stage i used alpine:3.16.7, a minimal Linux distribution helps reduce the size of th image. I installed nodejs and npm manually in this stage, ensuring only the required runtime components are present. This resulted in a secure and lean image.

Front end
---------
The frontend also uses a multi-stage build. The first stage uses node:14-slim to install and build the web application. The second stage uses "nginx:alpine" to serve the static files. Nginx is a web server used to serve production builds of react applications. The alpine version of nginx helps reduce the size of the image.

Mongo-DB
-----
This was used because it doesnt require a lot of setup and it is easy to use. 

2. Dockerfile Directives Used in Each Container
-----------------------------------------------

### Backend

The backend Dockerfile uses a **multi-stage build**:

- `FROM node:14 AS build` – Uses the full Node.js image to install dependencies and copy the application code.
- `WORKDIR /usr/src/app` – Sets the working directory inside the container.
- `COPY package*.json ./` and `RUN npm install` – Installs dependencies based on the package files.
- `COPY . .` – Copies all application files.
- `FROM alpine:3.16.7` – Switches to a lightweight Alpine Linux image for the final build.
- `RUN apk update && apk add --no-cache nodejs npm` – Installs only necessary Node.js runtime for production.
- `COPY --from=build /usr/src/app /app` – Copies the prepared code from the build stage.
- `EXPOSE 5000` – Exposes port 5000 used by the Express server.
- `CMD ["node", "server.js"]` – Starts the backend server.

This combination ensures a clean, efficient image ready for production with minimal dependencies.

### Frontend

The frontend Dockerfile also uses a **multi-stage build**:

- `FROM node:14-slim AS build` – Slim variant of Node.js to reduce build size.
- `WORKDIR /usr/src/app` – Sets the working directory.
- `COPY package*.json ./` and `RUN npm install` – Installs React app project dependencies.
- `COPY . .` – Adds all the source code.
- `RUN npm run build` – To build a production ready react application.

The second stage:

- `FROM nginx:alpine` – Uses Nginx to serve static files efficiently.
- `COPY --from=build /usr/src/app/build /usr/share/nginx/html` – Places the React build output in Nginx’s root directory.
- `EXPOSE 80` – Exposes port 80.
- `CMD ["nginx", "-g", "daemon off;"]` – Starts Nginx in the foreground to keep the container running.

This approach ensures the app is served through a fast, lightweight web server.

### MongoDB

The MongoDB service uses the official `mongo` image, which includes its own entrypoint. No custom Dockerfile needed, and port `27017` was exposed for database access.



 3. Docker-compose Networking (Port allocation for the app and a bridge network implementation)
 ----------------------------------------------------------------------------------------------
 I used bridge drivers because the bridge driver allows for isolated communication between containers while also enabling external traffic routing to exposed ports.
 I used a bridge network called `app.net` that i configured in docker-compose.yml. Through this network each service can resolve and communicate with each other using their repective container names. I have used custom ip adresses(subnet and ip range) to avoid conflicts with other docker networks.  
# port allocation
 front-end (mattfront-client)
 Mapped port 3000 on the host to container port 80, since the React build is served by Nginx.
 ports:
  - "3000:80"

 back-end (mattback-backend)
 Mapped port 5000 on the host to container port 5000, where the Express server runs.
 ports:
  - "5000:5000"

MongoDB (app-ip-mongo)
Exposed on port 27017, allowing local database inspection or testing if necessary.
 ports:
  - "27017:27017"

 4. Docker-compose Volume Definition and Usage
 ----------------------------------------------------------------------------------------------
To persist data generated by the MongoDB service across container restarts and rebuilds, I defined and used a named Docker volume in the `docker-compose.yml` file.
volumes:
  app-mongo-data:
    driver: local

This volume is mounted to the mongoDB as follows:
 volumes:
      - type: volume
        source: app-mongo-data
        target: /data/db

Docker volumes ensures that the database retains its state even if the container is stopped, removed, or rebuilt.     

 4. Git workflow
 ----------------------------------------------------------------------------------------------
After forking the project from the repository provided i cloned the project into my device using 
`git clone <repourl>`
I have used git add . to stage all the changes (new files, modifications, deletions) in my directory to be committed. All the changes have been pushed to master branch in the project.
i have made frequent commits at different stages throught the project.
A .gitignore file was used to prevent unnecessary files and directories.
After all the tests had been i finally used `git push` to push all the adjusted Dockerfiles, docker-compose and explation.md files.
